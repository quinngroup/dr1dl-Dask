{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "import scipy.linalg as sla\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "import psutil\n",
    "import sparse\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "\n",
    "from sklearn.datasets import make_sparse_coded_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:\t1\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "'''\n",
    "These inputs were copied from the pyspark version.\n",
    "I may not need all of these.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "input_data = ''\n",
    "T = 20 #Rows\n",
    "P = 20 #Cols\n",
    "\n",
    "#Optional\n",
    "R = int(0.07 * P) #Enforces sparcity \n",
    "M = 5 #Dimensionality of the learned dictionary\n",
    "E = 0.01 #Epsilon\n",
    "norm = True\n",
    "\n",
    "print(f'R:\\t{R}')\n",
    "#Spark Options, look for similar Dask elements\n",
    "partitions = 4*4\n",
    "execmem = '8g'\n",
    "\n",
    "#Outputs\n",
    "file_D = 'D.txt'\n",
    "file_z = 'z.txt'\n",
    "prefix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iterations = P*10\n",
    "seed = np.random.randint(max_iterations +1, high = 4294967295)\n",
    "S, D, SV = make_sparse_coded_signal(T,M,P,R,seed)\n",
    "S = da.from_array(S)\n",
    "u_new = da.zeros(T).compute()\n",
    "v = da.zeros(P).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "0\n",
      "<class 'numpy.ndarray'> <class 'dask.array.core.Array'>\n",
      "2020-01-27 22:58:50.973265\n",
      "204259328\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "1\n",
      "<class 'numpy.ndarray'> <class 'dask.array.core.Array'>\n",
      "2020-01-27 22:58:51.900638\n",
      "204275712\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "<class 'numpy.ndarray'> <class 'dask.array.core.Array'>\n",
      "2020-01-27 22:58:52.765399\n",
      "204275712\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "<class 'numpy.ndarray'> <class 'dask.array.core.Array'>\n",
      "2020-01-27 22:58:53.864704\n",
      "204275712\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dask.array.core.Array'>\n",
      "<class 'numpy.ndarray'>\n",
      "4\n",
      "<class 'numpy.ndarray'> <class 'dask.array.core.Array'>\n",
      "2020-01-27 22:58:55.665282\n",
      "204369920\n"
     ]
    }
   ],
   "source": [
    "for m in range(M):\n",
    "    #We need to broadcast the seed to create the initial random vector \n",
    "    #seed = np.random.randint(max_iterations +1, high = 4294967295)\n",
    "    _SEED_ = client.scatter(seed, broadcast=True)\n",
    "    np.random.seed(_SEED_.result())\n",
    "    \n",
    "    #Create a dense random vector\n",
    "    u_old = da.random.random(T)\n",
    "    num_iterations = 0\n",
    "    delta = 2*E\n",
    "    \n",
    "    while num_iterations < max_iterations and delta > E:\n",
    "        \n",
    "        _U_ = client.scatter(u_old, broadcast=True) \n",
    "            \n",
    "        v = da.dot(_U_.result(),S) \n",
    "        print(type(v))\n",
    "        #Grab the indices of the top R values in v for the sparse vector\n",
    "        indices = sorted(v.argtopk(R,axis=0))\n",
    "        \n",
    "        #let's make the sparse vector.\n",
    "        sv = sparse.COO(indices,v[indices].compute(),shape=(P),sorted=True)\n",
    "        sv = da.from_array(sv)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Broadcast the sparse vector.\n",
    "        _V_ = client.scatter(sv,broadcast=True)\n",
    "\n",
    "        # P1: Matrix-vector multiplication step. Computes u.\n",
    "        u_new = da.dot(S,_V_.result()) \n",
    "        \n",
    "        \n",
    "        # Subtract off the mean and normalize.\n",
    "        u_new -= u_new.mean()\n",
    "        u_new /= da.linalg.norm(u_new)\n",
    "        u_new = u_new.compute()\n",
    "        print(type(u_new))\n",
    "        # Update for the next iteration.\n",
    "        delta = sla.norm(u_old - u_new) #Should u_old be _U_?\n",
    "        u_old = u_new\n",
    "        num_iterations += 1\n",
    "        \n",
    "    # Save the newly-computed u and v to the output files;\n",
    "    with open(file_D, \"a+\") as fD:\n",
    "        np.savetxt(fD, u_new, fmt = \"%.6f\", newline = \" \")\n",
    "        fD.write(\"\\n\")\n",
    "    with open(file_z, \"a+\") as fz:\n",
    "        np.savetxt(fz, sv.compute().todense(), fmt = \"%.6f\", newline = \" \")\n",
    "        fz.write(\"\\n\")\n",
    "\n",
    "    \n",
    "    # P4: Deflation step. Update the primary data matrix S. \n",
    "    _U_ = client.scatter(u_new, broadcast=True)\n",
    "    _V_ = client.scatter(sv, broadcast=True)\n",
    "\n",
    "    \n",
    "    #if args['debug']: print(m)\n",
    "    print(m)\n",
    "    print(type(_U_.result()),type(_V_.result()))\n",
    "    S -= da.outer(_U_.result(),_V_.result().compute().todense())\n",
    "    S.compute()\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    #if args['debug']: print(datetime.datetime.now())\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(process.memory_info().rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
