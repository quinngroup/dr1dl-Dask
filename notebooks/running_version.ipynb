{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "import scipy.linalg as sla\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "import psutil\n",
    "import sparse\n",
    "import operator\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask.bag import read_text\n",
    "import dask.array as da\n",
    "\n",
    "from sklearn.datasets import make_sparse_coded_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparcity:\t7\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "'''\n",
    "These inputs were copied from the pyspark version.\n",
    "I may not need all of these.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "input_data = ''\n",
    "T = 100 #Rows\n",
    "P = 100 #Cols\n",
    "\n",
    "#Optional\n",
    "R = int(0.07 * P) #Enforces sparcity \n",
    "M = 15 #Atoms of the learned dictionary\n",
    "E = 0.01 #Epsilon\n",
    "norm = True\n",
    "\n",
    "print(f'Sparcity:\\t{R}')\n",
    "#Spark Options, look for similar Dask elements\n",
    "partitions = 4*4  #Chunks?\n",
    "execmem = '8g'    \n",
    "\n",
    "#Outputs\n",
    "file_D = 'D.txt'\n",
    "file_z = 'z.txt'\n",
    "prefix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iterations = P*10\n",
    "seed = np.random.randint(max_iterations +1, high = 4294967295)\n",
    "S, D, SV = make_sparse_coded_signal(T,M,P,R,seed)\n",
    "S = da.from_array(S)\n",
    "S -= S.mean()\n",
    "S /= sla.norm(S,axis = 0)\n",
    "\n",
    "\n",
    "u_new = da.zeros(T)\n",
    "v = da.zeros(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "0:\t8 iterations\n",
      "0\n",
      "2020-02-15 16:32:35.514387\n",
      "333496320\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "1:\t4 iterations\n",
      "1\n",
      "2020-02-15 16:32:37.672901\n",
      "334376960\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "2:\t8 iterations\n",
      "2\n",
      "2020-02-15 16:32:42.058429\n",
      "337108992\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "3:\t11 iterations\n",
      "3\n",
      "2020-02-15 16:32:48.556386\n",
      "340762624\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "4:\t6 iterations\n",
      "4\n",
      "2020-02-15 16:32:52.571757\n",
      "343293952\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "5:\t8 iterations\n",
      "5\n",
      "2020-02-15 16:32:57.537098\n",
      "346980352\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "6:\t6 iterations\n",
      "6\n",
      "2020-02-15 16:33:01.720178\n",
      "362045440\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "7:\t6 iterations\n",
      "7\n",
      "2020-02-15 16:33:05.726371\n",
      "364605440\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "8:\t6 iterations\n",
      "8\n",
      "2020-02-15 16:33:09.803390\n",
      "367534080\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "9:\t6 iterations\n",
      "9\n",
      "2020-02-15 16:33:14.149008\n",
      "370618368\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "10:\t5 iterations\n",
      "10\n",
      "2020-02-15 16:33:17.798484\n",
      "373415936\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - '<' not supported between instances of 'NoneType' and 'NoneType'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/utils.py\", line 662, in log_errors\n",
      "    yield\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 1729, in graph_doc\n",
      "    graph = TaskGraph(scheduler, sizing_mode=\"stretch_both\")\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 1123, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 39, in __init__\n",
      "    self.scheduler, dependencies=dependencies, priority=priority\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 43, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'\n",
      "tornado.application - ERROR - Uncaught exception GET /graph (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/graph', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/web.py\", line 1699, in _execute\n",
      "    result = await result\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/bokeh/server/views/doc_handler.py\", line 56, in get\n",
      "    session = yield self.get_session()\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/bokeh/server/views/session_handler.py\", line 79, in get_session\n",
      "    session = yield self.application_context.create_session_if_needed(session_id, self.request)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/bokeh/server/contexts.py\", line 222, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/bokeh/application/application.py\", line 178, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/bokeh/application/handlers/function.py\", line 133, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 1729, in graph_doc\n",
      "    graph = TaskGraph(scheduler, sizing_mode=\"stretch_both\")\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 1123, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 39, in __init__\n",
      "    self.scheduler, dependencies=dependencies, priority=priority\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 43, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'\n",
      "Exception ignored in: <function TaskGraph.__del__ at 0x1c29778f28>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calebcrumley/anaconda3/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 1277, in __del__\n",
      "    self.scheduler.remove_plugin(self.layout)\n",
      "AttributeError: 'TaskGraph' object has no attribute 'layout'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "11:\t11 iterations\n",
      "11\n",
      "2020-02-15 16:33:24.055010\n",
      "379899904\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "12:\t4 iterations\n",
      "12\n",
      "2020-02-15 16:33:26.653247\n",
      "382459904\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "13:\t6 iterations\n",
      "13\n",
      "2020-02-15 16:33:30.027731\n",
      "386650112\n",
      "Lets start the inner loop\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "14:\t6 iterations\n",
      "14\n",
      "2020-02-15 16:33:33.246956\n",
      "390717440\n"
     ]
    }
   ],
   "source": [
    "for m in range(M):\n",
    "    #We need to broadcast the seed to create the initial random vector \n",
    "    #seed = np.random.randint(max_iterations +1, high = 4294967295)\n",
    "    _SEED_ = client.scatter(seed, broadcast=True)\n",
    "    np.random.seed(_SEED_.result())\n",
    "    \n",
    "    #Create a dense random vector\n",
    "    u_old = da.random.random(T)\n",
    "    u_old -= u_old.mean()\n",
    "    u_old /= sla.norm(u_old,axis = 0)\n",
    "    num_iterations = 0\n",
    "    delta = 2*E\n",
    "    print('Lets start the inner loop')\n",
    "    # Start the inner loop: this learns a single atom.\n",
    "    while num_iterations < max_iterations and delta > E:\n",
    "        \n",
    "        _U_ = client.scatter(u_old, broadcast=True) \n",
    "        v = da.matmul(_U_.result(),S) #May get an error here because S may be a future instead of a dask array\n",
    "        print(v.shape)\n",
    "        #Grab the indices and data of the top R values in v for the sparse vector\n",
    "        indices = v.argtopk(R).compute()\n",
    "        \n",
    "        data = v[indices].compute()  #Do I need to delete any of these intermediate variables? \n",
    "        #indices, data = client.compute(v.argtopk(R,axis=0), v.topk(R))\n",
    "        #let's make the sparse vector.\n",
    "        sv = sparse.COO(indices,data,shape=(P),sorted=False)\n",
    "        sv = da.from_array(sv)\n",
    "        \n",
    "        # Broadcast the sparse vector.\n",
    "        _V_ = client.scatter(sv,broadcast=True)\n",
    "\n",
    "        # P1: Matrix-vector multiplication step. Computes u.\n",
    "        u_new = da.matmul(S,_V_.result()) \n",
    "        print(u_new.shape)\n",
    "        \n",
    "        # Subtract off the mean and normalize.\n",
    "        u_new -= u_new.mean()\n",
    "        u_new /= sla.norm(u_new,axis = 0)\n",
    "        u_new = u_new.compute()\n",
    "        \n",
    "        # Update for the next iteration.\n",
    "        delta = sla.norm(u_old - u_new) #Should u_old be _U_?\n",
    "        u_old = u_new\n",
    "        num_iterations += 1\n",
    "    print(f'{m}:\\t{num_iterations} iterations')  \n",
    "    # Save the newly-computed u and v to the output files;\n",
    "    with open(file_D, \"a+\") as fD:\n",
    "        np.savetxt(fD, u_new, fmt = \"%.6f\", newline = \" \")\n",
    "        fD.write(\"\\n\")\n",
    "    with open(file_z, \"a+\") as fz:\n",
    "        np.savetxt(fz, sv.compute().todense(), fmt = \"%.6f\", newline = \" \")\n",
    "        fz.write(\"\\n\")\n",
    "\n",
    "    \n",
    "    # P4: Deflation step. Update the primary data matrix S. \n",
    "    _U_ = client.scatter(u_new, broadcast=True)\n",
    "    _V_ = client.scatter(sv, broadcast=True)\n",
    "\n",
    "    \n",
    "    #if args['debug']: print(m)\n",
    "    print(m)\n",
    "    \n",
    "    S -= da.blockwise(operator.mul, 'ij', _U_.result(), 'i', _V_.result(), 'j', dtype='f8')\n",
    "    \n",
    "    S.persist()\n",
    "    \n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    #if args['debug']: print(datetime.datetime.now())\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(process.memory_info().rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 80.00 kB </td> <td> 80.00 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (100, 100) </td> <td> (100, 100) </td></tr>\n",
       "    <tr><th> Count </th><td> 81 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">100</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<sub, shape=(100, 100), dtype=float64, chunksize=(100, 100), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.6986661 , 13.49704217, 14.49478104, 14.34828753, 11.16741423,\n",
       "       13.20684787, 14.31670847, 11.90125564, 12.25993799, 14.7672654 ,\n",
       "       14.02872351, 14.69641608, 15.44056484, 14.0873929 , 13.19715546,\n",
       "       12.199339  , 12.82789967, 14.69915729, 12.15378403, 13.30849708,\n",
       "       13.35539721, 14.74513007, 14.47226637, 15.72075073, 16.7174969 ,\n",
       "       15.00006601, 12.88702554, 12.00029295, 13.7919594 , 12.53961338,\n",
       "       13.44753476, 12.72551379, 13.61387412, 12.32757044, 14.08852618,\n",
       "       14.50861203, 13.42515142, 12.53537786, 15.05712115, 13.94881751,\n",
       "       12.42585336, 11.19918476, 13.17296569, 11.55884996, 13.43687351,\n",
       "       14.71668385, 14.38711415, 11.54125892, 13.5259135 , 14.02797357])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = da.random.random(50).compute()\n",
    "matrix = da.random.random((50,50))\n",
    "da.matmul(matrix,vector).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
